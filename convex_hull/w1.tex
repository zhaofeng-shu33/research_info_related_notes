\documentclass{article}
\usepackage{bm}
\usepackage{bbm}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{algorithm,algorithmic}
\usepackage{url}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{hyperref}
\newtheorem{theorem}{Theorem}
\newtheorem{example}{Example}
\newtheorem{lemma}{Lemma}
\DeclareMathOperator{\erf}{erf}
\title{A stochastic convex hull problem}
\begin{document}
\maketitle
\section{Two dimensions}
$(x_i, y_i) \sim p(x,y)$ are i.i.d. distributions
for $i=1,2,\dots, n, n+1$. We consider the event
$A_n =\{(x_{n+1}, y_{n+1}) \in ConvexHull\{(x_1, y_1),
\dots, (x_n, y_n)\} \}$. We give a lower bound on $A_n^c$
(complement) as follows:
\begin{theorem}\label{thm:lower_bound}
    \begin{equation}
        P(A_n^c) \geq \frac{2}{n+1}
    \end{equation}
\end{theorem}
\begin{proof}
We use the method of projection to prove Theorem
\ref{thm:lower_bound}.
Consider a direction $(\cos\theta, \sin \theta)$
characterized by $\theta$. The projection of $(x_i, y_i)$
is given by $x_i \cos\theta + y_i \sin \theta$.
If $\exists \theta$ such that
$x_{n+1}\cos\theta + y_{n+1} \sin \theta$
is larger than $\max_{i=1,\dots, n} \{x_{i}\cos\theta +
y_{i} \sin \theta\}$ or smaller than
$\min_{i=1,\dots, n} \{x_{i}\cos\theta +
y_{i} \sin \theta\}$, $A_n^c$ happens.
Let $z_i = x_i \cos \theta + y_i \sin \theta$,
$z_{\max}=\max\{z_1, \dots, z_n\}$ and
$z_{\min}=\min\{z_1, \dots, z_n\}$.
Then we have $P(A_n^c) \geq P(\exists \theta, z_{n+1} > z_{\max})
+ P(\exists \theta, z_{n+1} < z_{\min})
\geq P(\theta=\theta', z_{n+1} > z_{\max})
+ P(\theta=\theta', z_{n+1} < z_{\min}) $.

Now we compute $P(z_{n+1} > z_{\max})$
for a number $\theta'$.
The PDF of $z=x\cos \theta' + y \sin \theta'$
is given as $p(z)=\int
\frac{p(x, \frac{z-x \cos \theta'}
{\sin \theta'})}{|\sin \theta'|}dx$.
$P(z_{n+1} > z_{\max}) = \int P(z_{\max} < z)p(z)dz
= \int F(z)^n p(z)dz$ where $F(z)$ is the CDF of the
random variable $Z$. Therefore, the integral evaluates
to $\frac{1}{n+1}$. Similarly,
$P(\theta=\theta', z_{n+1} < z_{\min})=
\frac{1}{n+1}$.
\end{proof}

A case for Gaussian.
Suppose $p(x,y)=\frac{1}{2\pi}\exp(-\frac{x^2}{2}
-\frac{y^2}{2})$,
then the exact formula for $P(A_n^c)$
is
\begin{equation}\label{eq:gaussian_2d}
    P(A_n^c) = \frac{n}{\sqrt{\pi}} \int_{-\infty}^{+\infty}
    \Phi^{n-1}(u)e^{-u^2}du
\end{equation}
where $\Phi$ is the CDF of standard normal distribution.
We are interested in the decaying rate of $P(A_n^c)$
when $n\to \infty$, which is given in Lemma \ref{lem:gaussian}
\begin{lemma}\label{lem:gaussian}
The equation in \eqref{eq:gaussian_2d} has decaying rate
$\frac{\sqrt{2}\pi}{n+1}$ as $n\to \infty$.
\end{lemma}
\begin{proof}
A similar argument can be used to show that
\begin{theorem}
\begin{equation}
P(A_n) \geq \frac{1}{n+1}
\end{equation}
\end{theorem}
\begin{proof}
Let $z_i=\sqrt{x_i^2+y_i^2}$.
If
$z_{n+1} \leq z_{\min}=\min\{z_1, \dots, z_n\}$,
it implies that $z_{n+1} \leq $

\end{proof}
First use integration by parts:
\begin{align*}
    P(A_n^c) &= \sqrt{2} \int_{-\infty}^{+\infty}
    e^{-u^2/2}d\Phi^n(u)
    =\sqrt{2} \int_{-\infty}^{+\infty}\Phi^n(u)
    ue^{-u^2/2}du \\
    &=2\sqrt{\pi} \int_{-\infty}^{+\infty}
    \Phi(u)^n ud\Phi(u)
\end{align*}
Then use change of variables ($y=\Phi^{n+1}(u)$):
\begin{align*}
    P(A_n^c) 
    =2\sqrt{\pi} \int_{0}^{1}z^n \Phi^{-1}(z)dz
\end{align*}
Using the relationship
$\Phi^{-1}(z)
= \sqrt{2} \erf^{-1}(2z-1)$
where $\erf$ is the error function,
we have
\begin{align*}
    P(A_n^c) 
    =\sqrt{2\pi} \int_{-1}^{1}
    \left(\frac{x+1}{2} \right)^n
    \erf^{-1} (x)dx
\end{align*}
Below we give a lower bound for $P(A_n^c)$
\begin{lemma}\label{lem:bound_erf_integral}
    \begin{align}
        \int_{-1}^{1}
    \left(\frac{x+1}{2} \right)^n
    \erf^{-1} (x)dx & \geq \sqrt{\pi}
    \left[\frac{2}{n+2} - \frac{1}{n+1}\right]
    \end{align}
\end{lemma}
Combining Lemma \ref{lem:bound_erf_integral},
we have $P(A_n^c) \geq  \frac{\sqrt{2}\pi}{n+1}$
approximately, which is a more tight lower bound than
Theorem \ref{thm:lower_bound}.

\end{proof}

\section{A high dimensional ball}
Suppose $X$ is an n dimensional random gaussian vector
sampled from
$\mathcal{N}(\bm{0}, I_n)$. The upper bound of probability that it
falls within a hyperball with radius $R$ is computed
as follows:
\begin{align*}
    P(||X||\leq R) &= \int_{x_1^2 + \dots + x_n^2 \leq R^2}
    \frac{1}{(2\pi)^{n/2}}
    e^{-\frac{x_1^2 + \dots x_n^2}{2}}
    dx_1 \dots dx_n\\
    &= \frac{S_{n-1}(1) }{(2\pi)^{n/2}}
    \int_0^R r^{n-1} e^{-r^2/2}dr
    \\
    &=\frac{2\pi^{n/2}}{(2\pi)^{n/2}\Gamma(n/2)}
    \int_0^R r^{n-1} e^{-r^2/2}dr \\
    &=\frac{2\pi^{n/2}}{(2\pi)^{n/2}\Gamma(n/2)}
    \int_0^R r^{n-1} e^{-r^2/2}dr \\
    &=\frac{1}{\Gamma(n/2)}
    \int_0^{\frac{R^2}{2}} x^{\frac{n}{2} - 1} e^{-x}dx\\
    &=\frac{\gamma(n/2, \frac{R^2}{2})}{\Gamma(n/2)}
\end{align*}
We can use the recurrence relation for the
incomplete gamma function $\gamma(s,x)$:
\begin{equation}
    \gamma(s+1, x)
    = s\gamma(s, x) - x^s e^{-x}
\end{equation}
We consider the recurrence formula for the
following sequence:
$a_{n+1} = n a_n - bk^n$.
Dividing both sides by $n!$, we obtain
$\frac{a_{n+1}}{n!} =
\frac{a_n}{(n-1)!} - b\frac{k^n}{n!}$.
Therefore, $\frac{a_n}{(n-1)!} = a_1 - b\sum_{i=1}^{n-1}
\frac{k^i}{i!}$ while $a_1 = \gamma(1, k)=1-e^{-k}$
and $b=e^{-k}$.
$\frac{a_n}{(n-1)!} = e^{-k}(e-\sum_{i=0}^{n-1} \frac{k^i}{i!})
\sim e^{-k}\frac{k^n}{n!}$.
Therefore, suppose $n$ is an even number,
$P(||X||\leq R) \sim e^{-k}\frac{(R^2/2))^n}{n!}$.
The decaying rate is faster than exponential rate.

A looser bound is obtained by replacing the hyperball
with a bounding hypercube. Then
$P(||X||\leq R) \leq P(|X_1|\leq R)^n$, which is an
exponential rate.
\section{Crofton's formula}
This part mainly consults \cite{crofton}.

Crofton's formula gives a way to compute the arc length
by integration. Suppose we have a two dimensional
parametrized curve $\gamma: [0, 1] \to \mathbb{R}^2$.
Then the arc length of $\gamma$ is
\begin{equation}\label{eq:gamma}
    len(\gamma) = \frac{1}{2}\iint n(p, \theta)
    dp d\theta
\end{equation}
where $p, \theta$ is the polar coordinate representation
of a straight line. $n(p, \theta)$ is the number of times the 
straight line intersects the curve. The integration
in \eqref{eq:gamma} is over $p\in [0, +\infty)$
and $\theta \in [0, 2\pi]$.
\begin{example}
    The perimeter of the circle $x^2+y^2=r^2$.
    Using the integration formula \eqref{eq:gamma},
    we obtain $\frac{1}{2}\int_{0}^{2\pi} d\theta \int_0^r 2 dp=2\pi r$.
\end{example}
\begin{example}
    The line segment $0\leq x \leq 1, y=0$.
    The integral is $\frac{1}{2}\int_0^1 2 dp
    \int_0^{\arccos p} d\theta =
    \int_0^1 \arccos p dp=1$.
\end{example}
\begin{thebibliography}{9}
    \bibitem{crofton} \url{https://math.osu.edu/sites/math.osu.edu/files/What%20is%202017%20Croftons%20Formula.pdf}
\end{thebibliography}
\end{document}



